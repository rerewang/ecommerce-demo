# RAG 与混合检索实施指南：从 MVP 到生产级最佳实践

## 1. 架构概览

本指南记录了为电商 Chatbot 实施**混合检索 (Hybrid Search)** 系统的全过程、关键决策点及未来演进路线。

- **核心技术栈**: Next.js (App Router) + Supabase (PostgreSQL/pgvector) + AI SDK。
- **模型**:
  - Embedding (向量化): `BAAI/bge-m3` (SiliconFlow)。选用理由：支持多语言（中英互搜），1024 维，性能与成本平衡极佳。
  - LLM (对话): `DeepSeek-V3` (SiliconFlow)。
- **检索策略**: **RRF (Reciprocal Rank Fusion)**，融合 **Vector Search** (语义召回) 与 **Full Text Search** (关键词召回)。

---

## 2. 关键挑战与实战解决方案

### 2.1 “长尾噪音”问题 (iPad 乱入事件)
**现象**: 用户搜索“油画”，结果前 3 名是油画，但第 4-5 名出现了“iPad”和“键盘”。
**根因分析**:
- **向量检索特性**: 总是返回 Top K 个结果。如果库中只有 3 个真正相关的商品（相似度 > 0.5），它会被迫用库中“最不坏”的无关商品填满剩下的名额（例如 iPad，相似度 ~0.3）。
- **RRF 算法缺陷**: RRF 基于**相对排名 (Rank)** 而非绝对分数。在 RRF 眼中，第 4 名的 iPad 和第 3 名的油画仅仅差一个位次，得分非常接近。即使 iPad 实际上很不相关，RRF 也会给它较高的融合权重，导致它出现在最终列表中。
**实施的解决方案**:
- **向量截断 (Similarity Thresholding)**: 在数据库函数中增加硬性过滤 `WHERE (1 - (embedding <=> query)) > 0.5`。
- **效果**: 直接切断低质量的尾部结果。如果只有 3 个商品达标，就只返回 3 个，宁缺毋滥。这是防止 RAG 产生幻觉（把 iPad 当油画推荐）的最有效手段。

### 2.2 跨语言检索困境 (中文搜英文库)
**现象**: 用户搜“布偶猫”，FTS (全文检索) 贡献为 0。
**根因分析**:
- 数据库内容是英文 (`name: "Ragdoll Cat"`)，且 `fts` 索引是用 `'english'` 配置构建的（存储词干 `'ragdol'`, `'cat'`）。
- 查询词是中文。虽然 Postgres 能将“布偶猫”切分为 Token，但中文 Token `'布偶猫'` 永远无法匹配英文 Token `'ragdol'`。
**实施的解决方案 (Trust the Vector)**:
- 在 MVP 阶段，我们选择**完全信任向量模型**。`bge-m3` 是经过海量多语言语料训练的，它能够理解“布偶猫”的向量与 “Ragdoll Cat” 的向量在空间中是极度接近的。
- 只要加上 2.1 中的**阈值过滤**，向量检索就能精准召回英文商品，完全绕过了 FTS 的语言障碍。

### 2.3 AI SDK 兼容性陷阱
**现象**: 调用 Chatbot 时报 404 错误 (`/v1/responses`)。
**根因分析**: `@ai-sdk/openai` (v3.0.18) 针对新模型默认尝试使用 OpenAI 的 "Responses API" (实验性端点)。而 SiliconFlow 等第三方兼容层仅支持标准的 `/chat/completions`。
**解决方案**:
- **配置隔离**: 严格解耦 `EMBEDDING_*` 和 `OPENAI_*` 环境变量。避免不同服务混用同一个 Base URL 配置。
- **回退策略**: 代码从 `streamText` 回退到兼容性更好的 `ToolLoopAgent` 模式，确保走标准 Chat Completions 协议。

---

## 3. 进阶：大型电商的最佳实践路线图

虽然我们目前的方案对于 Demo/中小规模是完美的，但对于**千万级商品 (10M+)** 的大型电商，架构需要演进。

### 3.1 索引架构演进

| 阶段 | 方案 | 适用规模 | 优点 | 缺点 |
| :--- | :--- | :--- | :--- | :--- |
| **阶段 A (当前)** | **单表混合 (Single Table)** <br> `products` 表直接存 `vector` + `tsvector` | < 100k | 开发极快，事务一致性强 (ACID)，零运维成本。 | `SELECT *` 会拖慢性能 (Buffer Pool 污染)；更新锁竞争。 |
| **阶段 B** | **垂直拆分 (Vertical Split)** <br> 主表存业务数据，`product_search` 表存向量/索引 | < 10M | 解决 Buffer Pool 污染；更新价格不影响搜索表；Join 开销可控。 | 需要维护两张表的一致性。 |
| **阶段 C** | **搜索引擎卸载 (Offloading)** <br> Postgres 仅作 Source of Truth，同步到 ES/Milvus | > 10M | 极致的搜索性能；丰富的聚合/Facet 功能；存算分离。 | 架构复杂；引入同步延迟 (Eventual Consistency)；运维成本高。 |

### 3.2 国际化 (i18n) 搜索最佳实践

我们目前采用了“向量跨语言”方案，但如果是像 **亚马逊/淘宝** 这样对精确匹配要求极高的场景，通常会采用更复杂的策略：

1.  **多语言字段 (Explicit Columns)**:
    *   数据库结构：`name_en`, `name_zh`, `name_es`...
    *   索引策略：针对每一列建立对应的语言索引 (`fts_en`, `fts_zh`)。
    *   查询逻辑：`WHERE fts_en @@ query OR fts_zh @@ query`。这是最精确的。

2.  **查询翻译 (Query Translation Layer)**:
    *   在搜索发生前，先经过一个轻量级 LLM 或翻译服务。
    *   用户搜 "红色裙子" -> 翻译为 "Red Dress" -> 搜英文库。
    *   **优点**: 瞬间激活 FTS 精确匹配能力，无需改造数据库结构。

### 3.3 重排 (Re-ranking)
当前我们使用的是 RRF（无权重融合）。在更高级的场景中，会引入 **Cross-Encoder Re-ranker** (如 BGE-Reranker)：
1.  **召回 (Retrieval)**: 向量 + FTS 快速捞出 Top 100。
2.  **精排 (Re-ranking)**: 用 Cross-Encoder 模型对这 100 个结果逐一打分（精准但慢）。
3.  **截断**: 取 Top 10 返回。
*这能显著解决“向量觉得相似但其实是误匹配”的问题（如“手机壳”和“手机”向量很近，但重排能分清）。*

---

## 4. 常见认知误区澄清

### 误区 1：“数据库里的 Vector 都是一回事”
- **真相**:
  - **`vector` (pgvector)**: 存的是 1024 个浮点数。代表**语义** (Meaning)。用于找“意思相近的东西”。
  - **`tsvector` (FTS)**: 存的是词袋/词干。代表**符号** (Symbol)。用于找“字面包含的东西”。
  - *它们是两代完全不同的技术，互补而非替代。*

### 误区 2：“RRF 能自动解决排序问题”
- **真相**: RRF 是**排名放大器**。它不管分数绝对值，只管排名。如果你喂给它一堆低质量的“凑数”结果（例如排在第 4 的 iPad），RRF 会认为它和第 3 名差不多重要，从而把它推到前台。**必须在进入 RRF 之前进行过滤 (Pre-filtering)**。

### 误区 3：“相似度阈值可以固定为 0.5”
- **真相**: 0.5 只是 `bge-m3` 模型的一个经验值。换个模型（如 OpenAI Ada-002），0.5 可能意味着完全不相关。
- **最佳实践**: 生产环境应使用 **动态阈值** (例如：`Threshold = Top1_Score * 0.8`)，或者通过离线评测集定期校准固定阈值。
